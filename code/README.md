# Code README 

The code is provided for reference. 
Rerunning all the experiments would take a significant amount of compute. 
Our code was designed for our SLURM cluster and we did not test it on other systems.

If you find an issue with the code or missing files, please let us know!  

## Workspace and environment variables

The code relies on a `workspace` directory to save datasets, experiment results, plots and logs,
which is set by environment variables. To configure the environment variables, see `envs/readme.md`.

## Installation

To install the dependencies, including the specific version of `pytorch`, see `requirements/readme.md`.
Once the dependencies are installed, the library can be installed using `pip install -e .` from the directory containing `setup.cfg`.

## Sanity checks

To check whether the library is installed correctly, try `python -c "import optexp"`.

# Usage 

## Downloading data 

In the release section, we provide the data for the experiments in the paper.
Download them and extract them to the `workspace` directory.
The directory structure should be 
```
$WORKSPACE$/
    datasets/       # should automatically download on first use
    experiments/    #
    plots/          #
    tokenizers/     #
    wandb_cache/    # cache for WANDB downloads
```

## Experiment structures

The file `src/optexp/experiments/__main__.py` contains a list of all experiments that can be run.

The experiments definitions are in `src/optexp/experiments/`, organized by subfolders.
Each file defines the model, optimizers, and grid-search over hyperparameters, 
and another file defines 

## Plotting 

(assuming you have downloaded the experiment data to the `workspace` directory)

The script `make_all_plots.sh` generates all the plots.

To plot the main figures in the paper, run `python src/optexp/experiments/paper_figures.py`.
Some of the figures that require additional processing are generated by scripts in `scripts`.
To plot data from a specific experiment, for example `src/optexp/experiments/toy_models/linreg_perclass.py`, use 
```
python linreg_perclass.py --plot
```
If the experiment has per-class statistics (usually indicated by the `_perclass.py` suffix), use 
```
python linreg_perclass.py --plot --perclass
```
to generate the additional plots.
The large-scale experiment on GPT2-small require the additional flag `--use_steps`.



## Wandb and running experiments

(Only required for running experiments!)

We use wandb as the backend to save experiment results and download data.
If an experiment has already run and is saved on the specified entity/project on wandb, 
the experiment will not run again (unless `--force` is passed).

Use the small experiment in `src/experiments/toy_models/linreg_perclass.py` to check whether the library works. 
To run the first experiment in the list and upload it to WANDB, use 
```
python linreg_perclass.py --test 
```
To run all of them by sending them to a slurm cluster, use 
```
python linreg_perclass.py --slurm
```

Once an experiment has been run and uploaded to WANDB, the data can be downloaded with 
```
python linreg_perclass.py --download 
```
and it can then be plotted.
If data from that experiment is already present in the `workspace` directory,
the library will not download it again.
Note: Some of our experiment (`bigger_models`) override the wandb project 
by using the context manager `UseWandbProject(WANDB_PROJECT)`.  

